# -*- coding: utf-8 -*-
"""Webscrapping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xSu8clK0hcS6QqSYKzsZoKI0aMTijnjP
"""

from urllib.request import urlopen as uReq
from bs4 import BeautifulSoup as soup

my_url=  "https://www.gutenberg.org/files/2638/2638-0.txt"
uClient= uReq(my_url)
page_html= uClient.read()
uClient.close()

uClient

page_html

page_soup= soup(page_html)
page_soup

page_soup.text

import re
import requests
the_idiot_url = 'https://www.gutenberg.org/files/2638/2638-0.txt'

def get_book(url):
    # Sends a http request to get the text from project Gutenberg
    raw = requests.get(url).text
    # Discards the metadata from the beginning of the book
    #start = re.search(r"\*\*\* START OF THIS PROJECT GUTENBERG EBOOK .* \*\*\*",raw ).end()
    # Discards the text starting Part 2 of the book
    #stop = re.search(r"II", raw).start()
    # Keeps the relevant text
    text = raw
    return text

def preprocess(sentence):
    return re.sub('[^A-Za-z0-9.]+' , ' ', sentence).lower()

book = get_book(the_idiot_url)
processed_book = preprocess(book)
print(processed_book)

print(len(re.findall('\\b[\.]?the\\b', processed_book,flags=re.I)))

pattern = re.compile("i+")
pattern.subn("I", processed_book)

re.findall('"[\w. ]+"',book)

re.findall('--[a-zA-Z]+',book)

len(re.findall('\d+',book))

pattern = re.compile("[aeiou]+[^ ]+",flags=re.I)
a=pattern.findall(processed_book)

a

len(a)

re.findall("PART \\b[IV]+\\b",get_book(the_idiot_url))

pattern = re.compile("\d{3}[-\s]?\d{3}[-\s]?\d{4}")

pattern.findall('''444-122-1234
123-122-78999
1234567890
111 123-23
67-7890-2019''')

pattern = re.compile("[A-Za-z0-9\_]+@[a-zA-Z]+.[a-zA-Z]+")

pattern.findall("""Anirudh@gmail.com
guptask_2@rknec.edu
Anirudh @ com
guptasj@rknec.edu
123 @.com
AC .com""")

import re
p= input("Input your password:- ")
x = True
while x:  
    if (len(p)<6 or len(p)>12):
        break
    elif not re.search("[a-z]",p):
        break
    elif not re.search("[0-9]",p):
        break
    elif not re.search("[A-Z]",p):
        break
    elif not re.search("[$#@]",p):
        break
    elif re.search("\s",p):
        break
    else:
        print("Valid Password")
        x=False
        break

if x:
    print("Not a Valid Password")

pattern = re.compile("<td>[^.]+</td>")

pattern.findall("""<tr align="center"><td>1</td> <td>Noah</td> <td>Emma</td></tr>
<tr align="center"><td>2</td> <td>Liam</td> <td>Olivia</td></tr>
<tr align="center"><td>3</td> <td>Mason</td> <td>Sophia</td></tr>
<tr align="center"><td>4</td> <td>Jacob</td> <td>Isabella</td></tr>
<tr align="center"><td>5</td> <td>William</td> <td>Ava</td></tr>
<tr align="center"><td>6</td> <td>Ethan</td> <td>Mia</td></tr>
<tr align="center"><td>7</td> <td HTML>Michael</td> <td>Emily</td></tr>
""")

import urllib.request
from re import findall
url = "https://www.summet.com/dmsi/html/codesamples/addresses.html" 
#url = "http://www.summet.com/dmsi/html/codesamples/addresses.html"
 
response = urllib.request.urlopen(url)
 
html = response.read()
 
htmlStr = html.decode()
 
pdata = findall("\(\d{3}\) \d{3}-\d{4}", htmlStr)
 
for item in pdata:
    print(item)

url = "https://www.geeksforgeeks.org/" 
response = urllib.request.urlopen(url)
 
html = response.read()
 
htmlStr = html.decode()

print(htmlStr)

pdata = findall("Python", htmlStr)

len(pdata)

